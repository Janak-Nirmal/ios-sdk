<h1>VisionIQ iOS SDK</h1>

<h2>Introduction</h2>

<p>IQ Engines provides VisionIQ, an image recognition platform that makes it possible to add visual search to your mobile application. Before diving into the details of how you can integrate the SDK into your iOS application, we give a brief overview of the two engines at the core of VisionIQ: (1) visual search in the cloud, and (2) visual search on the mobile device. You can find more information about VisionIQ <a href="http://www.iqengines.com/howitworks/">here</a>.</p>

<h3>Visual search in the cloud</h3>

<p>Visit our developer portal and <a href="http://www.iqengines.com/accounts/login/">sign up</a> for an API key. Once you have obtained your API key, you will be able to (1) send images to the VisionIQ cloud for image recognition via the Query API and (2) train the VisionIQ cloud with your own set of images via the Training API. In the iOS SDK search in the cloud is referred to as <em>remote</em> search, as the image processing algorithms are running on VisionIQ's remote servers.</p>

<p>When you send an image to the VisionIQ cloud, it is first analyzed by our computer vision algorithms, where we match your image against the VisionIQ image dataset as well as your private dataset of images. Contact us at support@iqengines.com if you want VisionIQ to search your dataset exclusively.     </p>

<p>When our computer vision algorithms are not able to recognize your image, then it is sent to our crowdsourcing engine, i.e. a person will manually tag your image. By combining computer vision and crowdsourcing, we are able to provide accurate labels for 100% of images. As using crowdsourcing is not appropriate for all applications, you can turn it on or off by contacting us at support@iqengines.com. </p>

<h3>Visual search on the mobile device</h3>

<p>The VisionIQ cloud can scale to recognize millions of images. However, if your dataset is small (~100 objects), then the recognition can happen entirely on the mobile device, with no need for an internet connection as the image isn't sent to the VisionIQ cloud. This makes for a really snappy experience, and quasi-instant results. In the iOS SDK the search on the mobile device is referred to as <em>local</em> search. If you switch the <em>continuous</em> mode on, then frames are continuously grabbed from the camera and processed in real-time, i.e. there is no need for the user to take an action such as pressing a button to retrieve information about objects within the viewfinder.  </p>

<h2>VisionIQ Example App</h2>

<p>The SDK comes with an example app that showcases all the functionality of VisionIQ. It provides a reference design for visual search. If you are building an app from scratch, the Example app will help you get started! The app is in the <code>ExampleApp</code> folder and you can configure it by editing the settings defined in the <code>Config.h</code> file: </p>

<ul>
<li><code>IQE_APIKEY</code> and <code>IQE_SECRET</code>: you can obtain your API key and secret by <a href="http://www.iqengines.com/accounts/register/">signing up</a> for VisionIQ. </li>
<li><em>remote</em> search
<ul>
<li><code>SEARCH_OBJECT_REMOTE</code>: if set to <code>YES</code>, <em>remote</em> search is enabled. </li>
</ul></li>
<li><em>local</em> search
<ul>
<li><code>SEARCH_OBJECT_LOCAL</code>: if set to <code>YES</code>, <em>local</em> search is enabled.</li>
<li><code>SEARCH_OBJECT_LOCAL_CONTINUOUS</code>: if set to <code>YES</code>, <em>local continuous</em> search is enabled.</li>
<li><code>SEARCH_BARCODE</code>: Detect barcode and QR codes if set to <code>YES</code>.</li>
</ul></li>
</ul>

<p>Note that the Example app does not work with the simulator as it is using the <code>AVFoundation</code> framework. However, you can run the Example app on your iOS device!</p>

<h2>How to include the SDK in your mobile app</h2>

<p>The VisionIQ iOS SDK is comprised of:</p>

<ul>
<li>The VisionIQ SDK in the <code>IQEngineSDK</code> folder. It contains all the necessary functions to include the VisionIQ functionality in your app. The two main classes are:
<ul>
<li>the <code>IQE</code> class: it contains all the functions for <em>local</em> and <em>remote</em> image recognition. You will use this class when integrating VisionIQ into your app.</li>
<li>the <code>IQEViewController</code> class: it is a <code>UIViewController</code> subclass, and provides an example of a user interface for visual search. It uses the <code>IQE</code> class.</li>
</ul></li>
<li>The VisionIQ demo application in the <code>ExampleApp</code> folder. It shows an example of how the SDK can be used in a mobile app, and uses the <code>IQEViewController</code> class.</li>
</ul>

<h3>Configure the IQEngines VisionIQ SDK</h3>

<p>When you import the IQEngines VisionIQ SDK in your app, you can configure it by setting the following variables in <code>IQEnginesSDK/IQEConfig.h</code>:</p>

<ul>
<li><code>IQENGINES_LOCAL_LIB</code>: If local search is not used, set to <code>FALSE</code>. IQEnginesSDK/Local/libIQEnginesLocal.a can then be removed from the project, which will make your app smaller.</li>
<li><code>IQE_IMAGE_CAPTURE</code>: Designates if the <code>IQEImageCapture</code> class is used by <code>IQE</code> to provide the image capture functionality. Set to <code>FALSE</code> if a custom image acquisition scheme will be used.</li>
</ul>

<h3>Using the IQEViewController class</h3>

<p>The steps to use the IQEViewController class are as follows:</p>

<ul>
<li>Add the IQEnginesSDK folder into your project.</li>
<li>Add additional frameworks and libraries to the project:
<ul>
<li><code>AVFoundation.framework</code></li>
<li><code>CoreLocation.framework</code></li>
<li><code>CoreMedia.framework</code></li>
<li><code>CoreVideo.framework</code></li>
<li><code>QuartzCore.framework</code></li>
<li><code>libiconv.dylib</code></li>
</ul></li>
<li>Local search uses the standard c++ library. If the project does not contain c++ source files (.mm or .cpp), link to the standard c++ library by adding -lstdc++ to "Other Linker Flags" in Build Settings, or link with libstdc++.dylib.</li>
<li>When using local object detection, add .desc/.kp data files and objects.json to the folder named: iqedata. Be sure to create folder references, not groups when adding this folder.</li>
<li>Import the IQEViewController header file.</li>
</ul>

<p>```</p>

<pre><code>    #import "IQEViewController.h"
</code></pre>

<p>```</p>

<ul>
<li>Allocate and initialize a IQEViewController object. Set the search type depending on what search is required. Use your IQ Engines API Key and secret if doing remote search:</li>
</ul>

<p>```</p>

<pre><code>    IQEViewController* vc = [[IQEViewController alloc] initWithParameters:IQESearchTypeAll
                                                                   apiKey:@""
                                                                apiSecret:@""];

    vc.delegate = self;
</code></pre>

<p>```</p>

<ul>
<li>Present the view controller via presentModalViewController:animated:</li>
</ul>

<p>```</p>

<pre><code>    [self presentModalViewController:vc animated:YES];
</code></pre>

<p>```</p>

<ul>
<li>Implement the IQEViewControllerDelegate delegate methods as necessary. Specifically, the iqeViewControllerDidCancel method:</li>
</ul>

<p>```</p>

<pre><code>    - (void) iqeViewControllerDidCancel:(IQEViewController*)controller
    {
        controller.delegate = nil;
        [controller dismissModalViewControllerAnimated:YES];
    }
</code></pre>

<p>```</p>

<h3>Using the IQE class</h3>

<p>The steps to use the IQE class from the IQ Engines SDK are as follows:</p>

<ul>
<li>Add the IQEnginesSDK folder into your project.</li>
<li>Add additional frameworks and libraries to the project:
<ul>
<li><code>AVFoundation.framework</code></li>
<li><code>CoreMedia.framework</code></li>
<li><code>CoreVideo.framework</code></li>
<li><code>QuartzCore.framework</code></li>
<li><code>libiconv.dylib</code></li>
</ul></li>
<li>Local search uses the standard c++ library. If the project does not contain c++ source files (.mm or .cpp), link to the standard c++ library by adding -lstdc++ to "Other Linker Flags" in Build Settings, or link with libstdc++.dylib.</li>
<li>When using local object detection, add .desc/.kp data files and objects.json to a folder named iqedata. Be sure to create folder references, not groups when adding this folder.</li>
<li>Add the IQE class and delegate to view controller header:</li>
</ul>

<p>```</p>

<pre><code>    #import "IQE.h"
    @interface ViewController : UIViewController &lt;IQEDelegate&gt;
    {
        IQE* iqengines;
    }
</code></pre>

<p>```</p>

<ul>
<li>Allocate and initialize an IQE object in the view controller init method. Set the search type depending on what search is required. Use your IQ Engines API Key and secret if doing remote search:</li>
</ul>

<p>```</p>

<pre><code>    iqengines = [[IQE alloc] initWithParameters:IQESearchTypeAll
                                         apiKey:@""
                                      apiSecret:@""];

    iqengines.delegate = self;
</code></pre>

<p>```</p>

<ul>
<li>Set up the camera preview layer in the view controller viewDidLoad method.</li>
</ul>

<p>```</p>

<pre><code>    CGRect rect = self.view.layer.bounds;
    iqengines.previewLayer.bounds = rect;
    iqengines.previewLayer.position = CGPointMake(CGRectGetMidX(rect),
    CGRectGetMidY(rect));

    [self.view.layer insertSublayer:iqengines.previewLayer atIndex:0];
</code></pre>

<p>```</p>

<ul>
<li>Start and stop camera processing in 'viewWillAppear:' and 'viewDidDisappear:'
respectively:</li>
</ul>

<p>```</p>

<pre><code>    - (void)viewWillAppear:(BOOL)animated
    {
        [super viewWillAppear:animated];

        [iqengines startCamera];
    }

    - (void)viewDidDisappear:(BOOL)animated
    {
        [super viewDidDisappear:animated];

        [iqengines stopCamera];
    }
</code></pre>

<p>```</p>

<ul>
<li>Capture a still image from the camera by calling the captureStillFrame method. Process the image in the didCaptureStillFrame IQEDelegate method:</li>
</ul>

<p>```</p>

<pre><code>    - (IBAction)onCameraButton:(id)sender
    {
        [iqengines captureStillFrame];
    }

    - (void)iqEngines:(IQE*)iqe didCaptureStillFrame:(UIImage*)image
    {
        NSString* qid = [iqengines searchWithImage:image];
    }
</code></pre>

<p>```</p>

<ul>
<li>Handle the image search result in the didCompleteSearch IQEDelegate method:</li>
</ul>

<p>```</p>

<pre><code>    - (void)iqEngines:(IQE*)iqe didCompleteSearch:(IQESearchType)type withResults:(NSDictionary*)results forQID:(NSString*)qid
    {
        NSLog(@"results:%@", results);
    }
</code></pre>

<p>```</p>

<ul>
<li>Implement other IQEDelegate delegate methods as necessary.</li>
<li>Clean up by adding the following in dealloc:</li>
</ul>

<p>```</p>

<pre><code>    iqengines.delegate = nil;
    [iqengines stopCamera];
    [iqengines release];
</code></pre>

<p>```</p>

<h3>Using the IQE class on iOS 3.0 - 3.2</h3>

<p>The image capture features are unavailable on iOS versions before 4.0. However, it is still possible to use the IQE class with a UIImage. </p>

<ul>
<li><p>AVFoundation framework must be weak linked to the project. Change the framework from "Required" to "Optional" in the Link Binary with Libraries section of the target Build Phases.</p></li>
<li><p>Get an image (with UIImagePickerController or other method) and call searchWithImage: on the IQE instance.</p></li>
</ul>

<p>```</p>

<pre><code>    - (void)imagePickerController:(UIImagePickerController *)picker didFinishPickingMediaWithInfo:(NSDictionary *)info
    {    
        UIImage* image = [info objectForKey:UIImagePickerControllerOriginalImage];

        [iqengines searchWithImage:image];
    }
</code></pre>

<p>```</p>

<h2>Questions</h2>

<p>Contact us at support@iqengines.com if you have any questions!</p>
